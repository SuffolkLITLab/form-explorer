{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4a33179",
   "metadata": {},
   "source": [
    "# Group Varaibles into Screens\n",
    "\n",
    "Takes in a list of AL variables and spits out suggested groupings. Here's what's going on:\n",
    "\n",
    "1. It reads in a list of fields (e.g., `[\"user_name\",\"user_address\"]`)\n",
    "2. Splits each field into words (e.g., turning `user_name` into `user name`)\n",
    "3. It then turns these ngrams/\"sentences\" into vectors using word2vec. \n",
    "4. For the collection of fields, it finds clusters of these \"sentences\" within the semantic space defined by word2vec. Currently it uses Affinity Propagation. See https://machinelearningmastery.com/clustering-algorithms-with-python/\n",
    "\n",
    "Load libraries and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d2ec317",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import spacy\n",
    "import numpy as np\n",
    "from numpy import unique\n",
    "from numpy import where\n",
    "from sklearn.cluster import AffinityPropagation\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895178c5",
   "metadata": {},
   "source": [
    "Before you run this next cell, make sure you have the referenced model downloaded. See https://stackoverflow.com/a/58855787 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "27b85bfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg') # this takes a while to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76a90acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reCase(text):\n",
    "    # a quick and dirty way to pull words out of\n",
    "    # snake_case, camelCase and the like.    \n",
    "    output = re.sub(\"(\\w|\\d)(_|-)(\\w|\\d)\",\"\\\\1 \\\\3\",text.strip())\n",
    "    output = re.sub(\"([a-z])([A-Z]|\\d)\",\"\\\\1 \\\\2\",output)\n",
    "    output = re.sub(\"(\\d)([A-Z]|[a-z])\",\"\\\\1 \\\\2\",output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2836fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_screens(fields=[],damping=0.7):\n",
    "    # Takes in a list (fields) and returns a suggested screen grouping\n",
    "    # Set damping to value >= 0.5 or < 1 to tune how related screens should be\n",
    "    \n",
    "    vec_mat = np.zeros([len(fields),300])\n",
    "    for i in range(len(fields)):\n",
    "        vec_mat[i] = [nlp(reCase(fields[i])).vector][0]\n",
    "\n",
    "    # create model\n",
    "    model = AffinityPropagation(damping=damping,random_state=4)\n",
    "    # fit the model\n",
    "    model.fit(vec_mat)\n",
    "    # assign a cluster to each example\n",
    "    yhat = model.predict(vec_mat)\n",
    "    # retrieve unique clusters\n",
    "    clusters = unique(yhat)\n",
    "\n",
    "    screens = {}\n",
    "    #sim = np.zeros([5,300])\n",
    "    i=0\n",
    "    for cluster in clusters:\n",
    "        this_screen = where(yhat == cluster)[0]\n",
    "        vars = []\n",
    "        j=0\n",
    "        for screen in this_screen:\n",
    "            #sim[screen]=vec_mat[screen] # use this spot to add up vectors for compare to list\n",
    "            vars.append(fields[screen])\n",
    "            j+=1\n",
    "        screens[\"screen_%s\"%i]=vars\n",
    "        i+=1\n",
    "\n",
    "    return screens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3b986a",
   "metadata": {},
   "source": [
    "## Try it out\n",
    "\n",
    "Use daming >= 0.5 or < 1 to tune the groupings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6f85342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'screen_0': ['users1_name',\n",
       "  'users1_birthdate',\n",
       "  'users1_address_line_one',\n",
       "  'users1_address_line_two',\n",
       "  'users1_address_city',\n",
       "  'users1_address_state',\n",
       "  'users1_address_zip',\n",
       "  'users1_phone_number',\n",
       "  'users1_email',\n",
       "  'users1_signature'],\n",
       " 'screen_1': ['plantiffs1_name',\n",
       "  'defendants1_name',\n",
       "  'petitioners1_name',\n",
       "  'respondents1_name'],\n",
       " 'screen_2': ['docket_number'],\n",
       " 'screen_3': ['trial_court_county'],\n",
       " 'screen_4': ['signature_date']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields= [\n",
    "        \"users1_name\",\n",
    "        \"users1_birthdate\",\n",
    "        \"users1_address_line_one\",\n",
    "        \"users1_address_line_two\",\n",
    "        \"users1_address_city\",\n",
    "        \"users1_address_state\",\n",
    "        \"users1_address_zip\",\n",
    "        \"users1_phone_number\",\n",
    "        \"users1_email\",\n",
    "        \"plantiffs1_name\",\n",
    "        \"defendants1_name\",\n",
    "        \"petitioners1_name\",\n",
    "        \"respondents1_name\",\n",
    "        \"docket_number\",\n",
    "        \"trial_court_county\",\n",
    "        \"users1_signature\",\n",
    "        \"signature_date\"\n",
    "        ]\n",
    "\n",
    "cluster_screens(fields,damping=0.7)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
