{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "- Have scaper identify and download forms in formats other than pdfs (e.g., doc and docx)\n",
    "- Add more jurisdictions/states\n",
    "\n",
    "# Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request, json \n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import date\n",
    "import os\n",
    "from os import walk\n",
    "import os.path\n",
    "from os import path\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reCase(text):\n",
    "    output = re.sub(\"(\\w|\\d)(_|-)(\\w|\\d)\",\"\\\\1 \\\\3\",text)\n",
    "    output = re.sub(\"([a-z])([A-Z]|\\d)\",\"\\\\1 \\\\2\",output)\n",
    "    output = re.sub(\"(\\d)([A-Z]|[a-z])\",\"\\\\1 \\\\2\",output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.parse import quote\n",
    "\n",
    "#!pip install PyPDF2\n",
    "import PyPDF2\n",
    "\n",
    "from io import StringIO # https://stackoverflow.com/a/18284900\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.converter import TextConverter\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfpage import PDFPage\n",
    "\n",
    "def convert(fname, pages=None):\n",
    "    if not pages:\n",
    "        pagenums = set()\n",
    "    else:\n",
    "        pagenums = set(pages)\n",
    "\n",
    "    output = StringIO()\n",
    "    manager = PDFResourceManager()\n",
    "    converter = TextConverter(manager, output, laparams=LAParams())\n",
    "    interpreter = PDFPageInterpreter(manager, converter)\n",
    "\n",
    "    infile = open(fname, 'rb') # python three change\n",
    "    for page in PDFPage.get_pages(infile, pagenums):\n",
    "        interpreter.process_page(page)\n",
    "    infile.close()\n",
    "    converter.close()\n",
    "    text = output.getvalue()\n",
    "    output.close\n",
    "    return text\n",
    "\n",
    "#def download_pdf(url,path,filename):\n",
    "#    filename = path+filename\n",
    "#    try:\n",
    "#        f = urlopen(url)\n",
    "#        with open(filename, \"wb\") as code:\n",
    "#            code.write(f.read())\n",
    "#        return filename\n",
    "#    except:\n",
    "#        return \"error\"\n",
    "    \n",
    "def download_pdf(url,path,filename):\n",
    "    try:\n",
    "        filename = path+filename\n",
    "\n",
    "        f = requests.get(url, stream=True, headers={'User-agent': 'Mozilla/5.0'})\n",
    "\n",
    "        with open(filename, \"wb\") as code:\n",
    "            #code.write(f.read())\n",
    "            code.write(f.content)\n",
    "\n",
    "        return convert(filename)\n",
    "    except:\n",
    "        return \"error\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download forms and meta data from UT courts\n",
    "\n",
    "Download forms and place them in the folder defined by `form_path` while creating a dataframe that you save to `csv_path`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>jurisdiction</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>group</th>\n",
       "      <th>url</th>\n",
       "      <th>filename</th>\n",
       "      <th>downloaded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ed1efd08e3304bdaa887db753509d666</td>\n",
       "      <td>UT</td>\n",
       "      <td>www.utcourts.gov</td>\n",
       "      <td>Community Service Worksheet Third District Juv...</td>\n",
       "      <td>3rd District Juvenile Court: Forms and Pamphlets</td>\n",
       "      <td>https://www.utcourts.gov/courts/juv/juvsites/3...</td>\n",
       "      <td>COMMUNITY%20SERVICE%20WORKSHEET-FRONT%20AND%20...</td>\n",
       "      <td>2021-11-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id jurisdiction            source  \\\n",
       "0  ed1efd08e3304bdaa887db753509d666           UT  www.utcourts.gov   \n",
       "\n",
       "                                               title  \\\n",
       "0  Community Service Worksheet Third District Juv...   \n",
       "\n",
       "                                              group  \\\n",
       "0  3rd District Juvenile Court: Forms and Pamphlets   \n",
       "\n",
       "                                                 url  \\\n",
       "0  https://www.utcourts.gov/courts/juv/juvsites/3...   \n",
       "\n",
       "                                            filename  downloaded  \n",
       "0  COMMUNITY%20SERVICE%20WORKSHEET-FRONT%20AND%20...  2021-11-03  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jur = \"UT\"\n",
    "source = \"www.utcourts.gov\"\n",
    "site = \"https://www.utcourts.gov/forms/\"\n",
    "form_path = \"../data/raw/www.utcourts.gov/forms/\"\n",
    "csv_path = \"../data/raw/www.utcourts.gov/\"\n",
    "\n",
    "try:\n",
    "    files_df = pd.read_csv(csv_path+\"form_data.csv\")\n",
    "except:\n",
    "    files_df = pd.DataFrame([],columns=[\"id\",\"jurisdiction\",\"source\",\"title\",\"group\",\"url\",\"filename\",\"downloaded\"])\n",
    "    files_df.to_csv(csv_path+\"form_data.csv\", index=False, encoding=\"utf-8\")   \n",
    "    \n",
    "files_df[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with urllib.request.urlopen(urllib.request.Request(site)) as url:\n",
    "    content = url.read().decode()\n",
    "soup = BeautifulSoup(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: https://www.utcourts.gov/howto/family/adoption/stepchild/docs/10_Decree.pdf\n"
     ]
    }
   ],
   "source": [
    "today = date.today().strftime(\"%Y-%m-%d\")\n",
    "body = soup.find('div',id=\"content\")\n",
    "i = 0\n",
    "limit = 5\n",
    "for section in re.split(\"<h3>\",str(body), flags=re.IGNORECASE):\n",
    "    group = re.match('^[^<]*',section)[0]\n",
    "    \n",
    "    #print(group)\n",
    "    \n",
    "    section_html = BeautifulSoup(section)\n",
    "    for li in section_html.find_all('li'):\n",
    "        title = re.sub('\\(.*\\s*.*','',li.text)\n",
    "        \n",
    "        #print(\"\\t\",i,title)\n",
    "        \n",
    "        for a in li.find_all('a', href=True):\n",
    "            if (re.search(\"^http.*\\.pdf\",a['href'])):\n",
    "                url = re.search(\".*/([^/]*)\\.pdf\",a['href'], re.IGNORECASE)\n",
    "                filename = url.group(1)+\".pdf\"\n",
    "                fileurl = url.group(0)\n",
    "                fileid = uuid.uuid4().hex\n",
    "                \n",
    "                #print(\"\\t\",filename,\"\\n\\t\",fileurl,\"\\n\")\n",
    "                \n",
    "                status = \"\"\n",
    "                if fileurl not in files_df[\"url\"].values:\n",
    "                    print(\"Downloading: \"+fileurl)\n",
    "                    if (i < limit):\n",
    "                        status = download_pdf(fileurl,form_path,fileid+\".pdf\")\n",
    "\n",
    "                    if status == \"error\":\n",
    "                        print(\"#######################\")\n",
    "                        print(\"         Error!!!\")\n",
    "                        print(\"#######################\")\n",
    "                        #time.sleep(5)\n",
    "                    else:\n",
    "                        if (i < limit):\n",
    "                            files_df = files_df.append(pd.DataFrame([[fileid,jur,source,title,group,fileurl,filename,today]],columns=[\"id\",\"jurisdiction\",\"source\",\"title\",\"group\",\"url\",\"filename\",\"downloaded\"]), ignore_index=True,sort=False)\n",
    "                            i += 1\n",
    "                        else:\n",
    "                            print(\"skip\")\n",
    "                        #time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(files_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df.to_csv(csv_path+\"form_data.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download forms and meta data from Michigan courts\n",
    "\n",
    "Download forms and place them in the folder defined by `form_path` while creating a dataframe that you save to `csv_path`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from requests_html import HTMLSession\n",
    "#from requests_html import AsyncHTMLSession\n",
    "#import nest_asyncio\n",
    "#import pyppdf.patch_pyppeteer\n",
    "\n",
    "#asession = AsyncHTMLSession()\n",
    "#r = await asession.get(\"https://www.courts.michigan.gov/SCAO-forms/appeals/\")\n",
    "#await r.html.arender(timeout=15, sleep=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jur = \"MI\"\n",
    "source = \"www.courts.michigan.gov\"\n",
    "form_path = \"../data/raw/www.courts.michigan.gov/forms/\"\n",
    "csv_path = \"../data/raw/www.courts.michigan.gov/\"\n",
    "\n",
    "today = date.today().strftime(\"%Y-%m-%d\")\n",
    "\n",
    "try:\n",
    "    files_df = pd.read_csv(csv_path+\"form_data.csv\")\n",
    "except:\n",
    "    files_df = pd.DataFrame([],columns=[\"id\",\"jurisdiction\",\"source\",\"title\",\"group\",\"url\",\"filename\",\"downloaded\"])\n",
    "    files_df.to_csv(csv_path+\"form_data.csv\", index=False, encoding=\"utf-8\")\n",
    "    \n",
    "files_df[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MI court site is all js rendered. So, I downloaded the rendered pages into `../data/raw/www.courts.michigan.gov/SCAO-forms/html/` and will deal with them there. I used `copy(document.body.innerHTML);` in console to grab the rendered page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MI_get(file):\n",
    "    global files_df\n",
    "\n",
    "    group = reCase(re.search(\".*/([^/]*)\\.html\",file, re.IGNORECASE).group(1))\n",
    "\n",
    "    with open(file) as f:\n",
    "        contents = f.read()\n",
    "    f.close()\n",
    "    soup = BeautifulSoup(contents)\n",
    "    body = soup.find('div',id=\"main-content\")\n",
    "\n",
    "    i = 0\n",
    "    limit = 1\n",
    "    for a in body.find_all('a', href=True):\n",
    "        if (re.search(\".*\\.pdf\",a['href'])):\n",
    "            title = a.text.strip()\n",
    "            url = re.search(\".*/([^/]*)\\.pdf\",a['href'], re.IGNORECASE)\n",
    "            filename = url.group(1)+\".pdf\"\n",
    "            fileurl = \"https://www.courts.michigan.gov\"+url.group(0)\n",
    "            fileid = uuid.uuid4().hex\n",
    "\n",
    "            #print(\"\\t\",title,group,filename,\"\\n\\t\",fileurl,\"\\n\")\n",
    "\n",
    "            status = \"\"\n",
    "            if fileurl not in files_df[\"url\"].values:\n",
    "                print(\"Downloading: \"+fileurl)\n",
    "                if (i < limit):\n",
    "                    status = download_pdf(fileurl,form_path,fileid+\".pdf\")\n",
    "\n",
    "                if status == \"error\":\n",
    "                    print(\"#######################\")\n",
    "                    print(\"         Error!!!\")\n",
    "                    print(\"#######################\")\n",
    "                    time.sleep(5)\n",
    "                else:\n",
    "                    if (i < limit):\n",
    "                        files_df = files_df.append(pd.DataFrame([[fileid,jur,source,title,group,fileurl,filename,today]],columns=[\"id\",\"jurisdiction\",\"source\",\"title\",\"group\",\"url\",\"filename\",\"downloaded\"]), ignore_index=True,sort=False)\n",
    "                        i += 1\n",
    "                    else:\n",
    "                        print(\"skip\")\n",
    "                    #time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/raw/www.courts.michigan.gov/html/\"\n",
    "f = []\n",
    "for (dirpath, dirnames, filenames) in walk(path):\n",
    "    f.extend(filenames)\n",
    "    break\n",
    "f1 = [file for file in f]\n",
    "\n",
    "for file in f1:\n",
    "    if re.search(\".*\\.html\",file):\n",
    "        #print(path+file)\n",
    "        MI_get(path+file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "display(files_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df.to_csv(csv_path+\"form_data.csv\", index=False, encoding=\"utf-8\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
