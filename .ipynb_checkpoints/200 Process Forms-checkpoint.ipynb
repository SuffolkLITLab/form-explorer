{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "- create downloadable csv for each jurisdiction\n",
    "- deal with duble field entries esp from the simple normalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.request, json \n",
    "from urllib.request import urlopen\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import PyPDF2\n",
    "\n",
    "import pikepdf\n",
    "\n",
    "import os\n",
    "from os import walk\n",
    "import os.path\n",
    "from os import path\n",
    "import numpy as np\n",
    "#!pip install py-readability-metrics\n",
    "from readability import Readability\n",
    "#!python -m nltk.downloader punkt\n",
    "\n",
    "import time\n",
    "from datetime import date\n",
    "\n",
    "import spacy\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from joblib import dump, load\n",
    "\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity# define matrix with all zero values\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(text):\n",
    "    output = nlp(str(text)).vector   \n",
    "    return output\n",
    "\n",
    "def norm(row):\n",
    "    try:\n",
    "        matrix = row.reshape(1,-1).astype(np.float64)\n",
    "        return normalize(matrix, axis=1, norm='l1')[0]\n",
    "    except Exception as e: \n",
    "        print(\"===================\")\n",
    "        print(row)\n",
    "        print(\"-------------------\")\n",
    "        print(e)\n",
    "        print(\"===================\")\n",
    "        #return np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "included_fields = load('../data/processed/ML/norm_fields/included_fields.joblib') \n",
    "jurisdictions = load('../data/processed/ML/norm_fields/jurisdictions.joblib') \n",
    "groups = load('../data/processed/ML/norm_fields/groups.joblib') \n",
    "clf_field_names = load('../data/processed/ML/norm_fields/clf_field_names.joblib') \n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def reformat_field(text,max_length=30):\n",
    "    # h/t https://towardsdatascience.com/nlp-building-a-summariser-68e0c19e3a93\n",
    "    \n",
    "    #print(text)\n",
    "    \n",
    "    orig_title = text.lower()\n",
    "    orig_title = re.sub(\"[^a-zA-Z]+\",\" \",orig_title)\n",
    "    orig_title_words = orig_title.split()\n",
    "   \n",
    "    deduped_sentence = []\n",
    "    for word in orig_title_words:\n",
    "        if word not in deduped_sentence:\n",
    "            deduped_sentence.append(word)\n",
    "            \n",
    "    filtered_sentence = [w for w in deduped_sentence if not w.lower() in stop_words]   \n",
    "\n",
    "    filtered_title_words = filtered_sentence\n",
    "    \n",
    "    characters = len(' '.join(filtered_title_words))\n",
    "    \n",
    "    if characters > 0:\n",
    "\n",
    "        words = len(filtered_title_words)\n",
    "        av_word_len = math.ceil(len(' '.join(filtered_title_words))/len(filtered_title_words))\n",
    "        x_words = math.floor((max_length)/av_word_len)\n",
    "\n",
    "\n",
    "        sim_mat = np.zeros([len(filtered_title_words),len(filtered_title_words)])# will populate it with cosine_similarity values \n",
    "        # for each word compared to other\n",
    "        for i in range(len(filtered_title_words)):\n",
    "            for j in range(len(filtered_title_words)):\n",
    "                if i != j:\n",
    "                    sim_mat[i][j] = cosine_similarity(nlp(filtered_title_words[i]).vector.reshape(1,300), nlp(filtered_title_words[j]).vector.reshape(1,300))[0,0]\n",
    "\n",
    "        try:\n",
    "            nx_graph = nx.from_numpy_array(sim_mat)\n",
    "            scores = nx.pagerank(nx_graph)# print final values of words\n",
    "            sorted_scores = sorted(scores.items(), key=lambda item: item[1], reverse=True)\n",
    "\n",
    "            if x_words > len(scores):\n",
    "                x_words=len(scores)\n",
    "\n",
    "            i = 0\n",
    "            new_title = \"\"\n",
    "            for x in filtered_title_words:\n",
    "                #print(scores[i],sorted_scores[x_words][1])\n",
    "                if scores[i] >= sorted_scores[x_words-1][1]: \n",
    "                    if len(new_title)>0: new_title+=\"_\"\n",
    "                    new_title += x\n",
    "                i+=1\n",
    "\n",
    "            return new_title\n",
    "        except:\n",
    "            return '_'.join(filtered_title_words)\n",
    "    else:\n",
    "        return re.sub(\"\\s+\",\"_\",text.lower())\n",
    "    \n",
    "\n",
    "def normalize_name(jur,group,n,per,last_field,this_field):\n",
    "    \n",
    "    # Add hard coded conversions maybe by calling a function\n",
    "    # if returns 0 then fail over to ML or otherway around poor prob -> check hard-coded\n",
    "\n",
    "    if this_field not in included_fields:\n",
    "        this_field = reCase(this_field)\n",
    "\n",
    "        out_put = re.sub(\"^(My\\s)?Name$\",\"users1_name\",this_field, flags=re.IGNORECASE)\n",
    "        out_put = re.sub(\"^Printed Name\\s?\\d*$\",\"users1_name\",out_put, flags=re.IGNORECASE)  \n",
    "        out_put = re.sub(\"^(DOB|Date of Birth|Birthday)$\",\"users1_birthdate\",out_put, flags=re.IGNORECASE)\n",
    "\n",
    "        out_put = re.sub(\"^(Street )?Address$\",\"users1_address_line_one\",out_put, flags=re.IGNORECASE)\n",
    "        out_put = re.sub(\"^City State Zip$\",\"users1_address_line_two\",out_put, flags=re.IGNORECASE)\n",
    "        out_put = re.sub(\"^City$\",\"users1_address_city\",out_put, flags=re.IGNORECASE)\n",
    "        out_put = re.sub(\"^Zip( Code)?$\",\"users1_address_zip\",out_put, flags=re.IGNORECASE)\n",
    "\n",
    "        out_put = re.sub(\"^Phone$\",\"users1_phone_number\",out_put, flags=re.IGNORECASE)\n",
    "        out_put = re.sub(\"^Email$\",\"users1_email\",out_put, flags=re.IGNORECASE)\n",
    "\n",
    "        out_put = re.sub(\"^(Court\\s)?Case\\s?(No|Number)?\\s?A?$\",\"docket_number\",out_put, flags=re.IGNORECASE)\n",
    "        out_put = re.sub(\"^File\\s?(No|Number)?\\s?A?$\",\"docket_number\",out_put, flags=re.IGNORECASE)\n",
    "\n",
    "        out_put = re.sub(\"^Date\\s?\\d*$\",\"signature_date\",out_put, flags=re.IGNORECASE)\n",
    "\n",
    "        conf = 1.0\n",
    "\n",
    "        if out_put==this_field:\n",
    "            params = []\n",
    "            for item in jurisdictions:\n",
    "                if jur== item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "            for item in groups:\n",
    "                if group== item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "            params.append(n)\n",
    "            params.append(per)\n",
    "            for vec in norm(vectorize(this_field)):\n",
    "                params.append(vec)\n",
    "            #for vec in norm(vectorize(last_field)):\n",
    "            #    params.append(vec)\n",
    "\n",
    "            for item in included_fields:\n",
    "                if last_field==item:\n",
    "                    params.append(1)\n",
    "                else:\n",
    "                    params.append(0)\n",
    "\n",
    "            pred = clf_field_names.predict([params])\n",
    "            prob = clf_field_names.predict_proba([params])\n",
    "\n",
    "            conf = prob[0].tolist()[prob[0].tolist().index(max(prob[0].tolist()))]\n",
    "            out_put = pred[0]\n",
    "            \n",
    "    else:\n",
    "        out_put = this_field\n",
    "        conf = 1\n",
    "            \n",
    "    if out_put in included_fields:\n",
    "        if conf >= 0:\n",
    "            return \"*\"+out_put,conf #+\"| was <i>%s</i> (%.2f conf)\"%(this_field,conf) #, conf\n",
    "        else:\n",
    "            return reformat_field(this_field),conf #+\"| was <i>%s</i> (%.2f conf)\"%(this_field,conf) #, conf\n",
    "    else:\n",
    "        return reformat_field(this_field),conf #+\"| was <i>%s</i> (%.2f conf)\"%(this_field,conf) #, conf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reCase(text):\n",
    "    output = re.sub(\"(\\w|\\d)(_|-)(\\w|\\d)\",\"\\\\1 \\\\3\",text.strip())\n",
    "    output = re.sub(\"([a-z])([A-Z]|\\d)\",\"\\\\1 \\\\2\",output)\n",
    "    output = re.sub(\"(\\d)([A-Z]|[a-z])\",\"\\\\1 \\\\2\",output)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pdf (file):\n",
    "    try:\n",
    "        pdfFile = PyPDF2.PdfFileReader(open(file, \"rb\"))\n",
    "        if pdfFile.isEncrypted:\n",
    "            try:\n",
    "                pdfFile.decrypt('')\n",
    "                #print ('File Decrypted (PyPDF2)')\n",
    "            except:\n",
    "                #\n",
    "                #\n",
    "                # This didn't go so well on my Windows box so I just ran this in the pdf folder's cmd:\n",
    "                # for %f in (*.*) do copy %f temp.pdf /Y && \"C:\\Program Files (x86)\\qpdf-8.0.2\\bin\\qpdf.exe\" --password=\"\" --decrypt temp.pdf %f\n",
    "                #\n",
    "                #\n",
    "                #\n",
    "                \n",
    "                command=\"cp \"+file+\" tmp/temp.pdf; qpdf --password='' --decrypt tmp/temp.pdf \"+file\n",
    "                os.system(command)\n",
    "                #print ('File Decrypted (qpdf)')\n",
    "                #re-open the decrypted file\n",
    "                pdfFile = PyPDF2.PdfFileReader(open(file, \"rb\"))\n",
    "        text = \"\"\n",
    "        for page in pdfFile.pages:\n",
    "            text = text + \" \" + page.extractText()\n",
    "        return text\n",
    "    except:\n",
    "        return \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_form(fileloc,title=None,jur=None,cat=None,normalize=1):\n",
    "    f = PyPDF2.PdfFileReader(fileloc)\n",
    "    npages = f.getNumPages()\n",
    "    ff = f.getFields()\n",
    "    if ff:\n",
    "        fields = list(ff.keys())\n",
    "    else:\n",
    "        fields = []\n",
    "    f_per_page = len(fields)/npages\n",
    "    text = read_pdf(fileloc)\n",
    "    try:\n",
    "        readbility = int(Readability(text).flesch_kincaid().grade_level)\n",
    "    except:\n",
    "        readbility = None\n",
    "    \n",
    "    if title is None:\n",
    "        title = reCase(re.search(\"(.*)\\n\",text).group(1).strip())\n",
    "        \n",
    "    if normalize==1:\n",
    "        i = 0 \n",
    "        length = len(fields)\n",
    "        last = \"null\"\n",
    "        new_fields = []\n",
    "        new_fields_conf = []\n",
    "        for field in fields:\n",
    "            #print(jur,cat,i,i/length,last,field)\n",
    "            this_field,this_conf = normalize_name(jur,cat,i,i/length,last,field)\n",
    "            new_fields.append(this_field)\n",
    "            new_fields_conf.append(this_conf)\n",
    "            last = field\n",
    "        \n",
    "        new_fields = [v + \"__\" + str(new_fields[:i].count(v) + 1) if new_fields.count(v) > 1 else v for i, v in enumerate(new_fields)]\n",
    "    else:\n",
    "        new_fields = fields\n",
    "    \n",
    "    stats = {\n",
    "            \"title\":title,\n",
    "            \"category\":cat,\n",
    "            \"pages\":npages,\n",
    "            \"reading grade level\": readbility,\n",
    "            \"avg fields per page\": f_per_page,\n",
    "            \"fields\":new_fields,\n",
    "            \"fields_conf\":new_fields_conf,\n",
    "            \"fields_old\":fields\n",
    "            }    \n",
    "    \n",
    "    my_pdf = pikepdf.Pdf.open(fileloc)\n",
    "    fields_too = my_pdf.Root.AcroForm.Fields\n",
    "    k =0\n",
    "    for field in new_fields:\n",
    "        fields_too[k].T = re.sub(\"^\\*\",\"\",field)\n",
    "        k+=1\n",
    "        \n",
    "    #f2.T = 'new_hospital_name'\n",
    "    filename = re.search(\"\\/(\\w*\\.pdf)$\",fileloc).groups()[0]\n",
    "    my_pdf.save('../data/processed/forms/%s'%(filename))\n",
    "    \n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': '',\n",
       " 'category': None,\n",
       " 'pages': 2,\n",
       " 'reading grade level': 14,\n",
       " 'avg fields per page': 16.5,\n",
       " 'fields': ['*users1_name__1',\n",
       "  '*users1_address_line_one',\n",
       "  '*users1_address_line_two',\n",
       "  '*users1_phone_number',\n",
       "  '*users1_email',\n",
       "  'undefined__1',\n",
       "  'plaintiff_petitioner',\n",
       "  '*docket_number',\n",
       "  'judge',\n",
       "  'defendant_respondent',\n",
       "  'commissioner_domestic_cases',\n",
       "  'city_state_country',\n",
       "  'undefined__2',\n",
       "  'signature__1',\n",
       "  '*users1_name__2',\n",
       "  'service_members_limited__1',\n",
       "  'board_district_court_judges__1',\n",
       "  'page__1',\n",
       "  'persons_name_row__1',\n",
       "  'service_mail_person__1',\n",
       "  'service_person_charge__1',\n",
       "  'persons_name_row__2',\n",
       "  'service_mail_person__2',\n",
       "  'service_person_charge__2',\n",
       "  'persons_name_row__3',\n",
       "  'service_mail_person__3',\n",
       "  'service_person_charge__3',\n",
       "  '*signature_date',\n",
       "  'signature__2',\n",
       "  '*users1_name__3',\n",
       "  'service_members_limited__2',\n",
       "  'board_district_court_judges__2',\n",
       "  'page__2'],\n",
       " 'fields_conf': [1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.9999996366120051,\n",
       "  0.5424166660186392,\n",
       "  1.0,\n",
       "  0.9999941855102024,\n",
       "  0.5423728207830948,\n",
       "  0.999999613513202,\n",
       "  0.9999999092938628,\n",
       "  0.9999997937825285,\n",
       "  0.9999999207734205,\n",
       "  1.0,\n",
       "  0.9999996205131004,\n",
       "  0.9999997901787985,\n",
       "  0.9999999175755557,\n",
       "  0.9999998816368904,\n",
       "  0.9999990521570863,\n",
       "  0.9999990519569337,\n",
       "  0.999999916617396,\n",
       "  0.9999990521570863,\n",
       "  0.9999990519569337,\n",
       "  0.9999996561352843,\n",
       "  0.99999913610902,\n",
       "  0.9999994419482826,\n",
       "  1.0,\n",
       "  0.9999997682271486,\n",
       "  1.0,\n",
       "  0.999999518473587,\n",
       "  0.9999999269048994,\n",
       "  0.9999998917597216],\n",
       " 'fields_old': ['Name',\n",
       "  'Address',\n",
       "  'City State Zip',\n",
       "  'Phone',\n",
       "  'Email',\n",
       "  'undefined',\n",
       "  'PlaintiffPetitioner',\n",
       "  'Case Number',\n",
       "  'Judge',\n",
       "  'DefendantRespondent',\n",
       "  'Commissioner domestic cases',\n",
       "  'city and state or country',\n",
       "  'undefined_2',\n",
       "  'Signature',\n",
       "  'Printed Name',\n",
       "  'Service Members Statement about Limited',\n",
       "  'Approved Board of District Court Judges March 26 2010',\n",
       "  'Page 1 of 2',\n",
       "  'Persons NameRow1',\n",
       "  'Service Address    Mail     Hand Delivery    Efiled     Email     Left at business With person in charge or in receptacle for deliveries     Left at home With person of suitable age and discretion residing there',\n",
       "  'Service Date    Mail     Hand Delivery    Efiled     Email     Left at business With person in charge or in receptacle for deliveries     Left at home With person of suitable age and discretion residing there',\n",
       "  'Persons NameRow2',\n",
       "  'Service Address    Mail     Hand Delivery    Efiled    Email     Left at business With person in charge or in receptacle for deliveries     Left at home With person of suitable age and discretion residing there',\n",
       "  'Service Date    Mail     Hand Delivery    Efiled    Email     Left at business With person in charge or in receptacle for deliveries     Left at home With person of suitable age and discretion residing there',\n",
       "  'Persons NameRow3',\n",
       "  'Service Address    Mail     Hand Delivery    Efiled    Email     Left at business With person in charge or in receptacle for deliveries     Left at home With person of suitable age and discretion residing there_2',\n",
       "  'Service Date    Mail     Hand Delivery    Efiled    Email     Left at business With person in charge or in receptacle for deliveries     Left at home With person of suitable age and discretion residing there_2',\n",
       "  'Date',\n",
       "  'Signature_2',\n",
       "  'Printed Name_2',\n",
       "  'Service Members Statement about Limited_2',\n",
       "  'Approved Board of District Court Judges March 26 2010_2',\n",
       "  'Page 2 of 2']}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#parse_form(\"../data/processed/www.utcourts.gov/forms/898269a99ff1c65be10b1ae35bb34ba469fc14b7301b7ed7b126d195.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "#parse_form(\"../data/processed/www.utcourts.gov/forms/2532cd2b6d3aaff8c47726a0abd168fb4e5cdb4977c065cd27bde8c7.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)\n",
    "parse_form(\"../data/processed/www.utcourts.gov/forms/6ec7576210513907e699b5adf3397639507c688801a60bc34c201984.pdf\",title=None,jur=\"UT\",cat=None,normalize=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_df_ut = pd.read_csv(\"../data/raw/www.utcourts.gov/form_data.csv\")\n",
    "files_df_mi = pd.read_csv(\"../data/raw/www.courts.michigan.gov/form_data.csv\")\n",
    "\n",
    "df = pd.concat([files_df_ut,files_df_mi],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"pages\"] = \"\"\n",
    "df[\"fields\"] = \"\"\n",
    "df[\"fields_conf\"] = \"\"\n",
    "df[\"fields_old\"] = \"\"\n",
    "df[\"f_per_p\"] = \"\"\n",
    "df[\"reading\"] = \"\"\n",
    "\n",
    "for index,row in df.iterrows():\n",
    "    if row[\"pages\"] == \"\":\n",
    "        try:\n",
    "            stats = parse_form(\"../data/processed/\"+row[\"source\"]+\"/forms/\"+row[\"id\"]+\".pdf\",row[\"title\"],row[\"jurisdiction\"],row[\"group\"],1)\n",
    "            df.at[index, 'pages'] = stats[\"pages\"]\n",
    "            df.at[index, 'fields'] = stats[\"fields\"]\n",
    "            df.at[index, 'fields_conf'] = stats[\"fields_conf\"]\n",
    "            df.at[index, 'fields_old'] = stats[\"fields_old\"]\n",
    "            df.at[index, 'f_per_p'] = stats[\"avg fields per page\"]\n",
    "            df.at[index, 'reading'] = stats[\"reading grade level\"]\n",
    "            #print(index)\n",
    "        except:\n",
    "            print(\"error: \"+\"../data/raw/\"+row[\"source\"]+\"/forms/\"+row[\"id\"]+\".pdf\")\n",
    "        \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/processed/form_data.csv\", index=False, encoding=\"utf-8\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system('cp ../data/processed/www.utcourts.gov/forms/* ../data/processed/forms/')\n",
    "#os.system('cp ../data/processed/www.courts.michigan.gov/forms/* ../data/processed/forms/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
